{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvwjihX7F7of"
   },
   "source": [
    "# **Sentiment Anaysis using BERT**\n",
    "\n",
    "### **What is Bert?**\n",
    "BERT stands for Bidirectional Encoder Representations from Transformers.It It is an open source machine learning framework for natural language processing (NLP) developed by **Google**.It is basically trained on large book corpus and we are gonna leverage that trained parameters for our tasks.\n",
    "\n",
    "## All right, Lets dive into the coding part\n",
    "\n",
    "We are gonna levearage free GPU's provided by Google in colab interactive platform for training our model.\n",
    "\n",
    "The followig code will test's for GPU and yeah! we got GPU. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "x0E9WfSkPmm4",
    "outputId": "470e6355-09e9-4407-bb34-aa6b1312e7fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not... \n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIXUTc5gKp7f"
   },
   "source": [
    "### Transformers\n",
    "Transfromers is an model arcitecture which uses stacked self-attention and point-wise, fully connected layers for both the encoder and decoder\n",
    " \n",
    "we will install this using following codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mzUCYiRFPtLr",
    "outputId": "bc5846fd-7a9e-4780-cfb8-9633de08fc2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (3.0.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.45.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2020.4.4)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.8.1rc1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.10)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKPkxBwhSq_P"
   },
   "source": [
    "Module for downloading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SJOfsDBuQAA6",
    "outputId": "ba7c9d9d-e44f-4332-bc4b-33e45d5408ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9681 sha256=11011ee7bca92aee90811a332ed63f0a26c44f1d68bb76c4ede25cbc94bd2f9c\n",
      "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzrRwphfUFoo"
   },
   "source": [
    "Downloading Dataset \"yelp reviews\" from fast.ai into our colab directory.\n",
    "you can learn more about fast.ai using this link https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/\n",
    "also you can download the dataset from here https://s3.amazonaws.com/fast-ai-nlp/yelp_review_full_csv.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AcdQrsXhQIPO",
    "outputId": "bb9cc92f-a003-4eff-c793-1db919f82c88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-27 07:04:01--  http://clone/\n",
      "Resolving clone (clone)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘clone’\n",
      "--2020-12-27 07:04:01--  https://s3.amazonaws.com/fast-ai-nlp/yelp_review_full_csv.tgz\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.207.189\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.207.189|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 196146755 (187M) [application/x-tar]\n",
      "Saving to: ‘yelp_review_full_csv.tgz’\n",
      "\n",
      "yelp_review_full_cs 100%[===================>] 187.06M  48.1MB/s    in 3.8s    \n",
      "\n",
      "2020-12-27 07:04:05 (48.6 MB/s) - ‘yelp_review_full_csv.tgz’ saved [196146755/196146755]\n",
      "\n",
      "FINISHED --2020-12-27 07:04:05--\n",
      "Total wall clock time: 4.3s\n",
      "Downloaded: 1 files, 187M in 3.8s (48.6 MB/s)\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "!wget clone https://s3.amazonaws.com/fast-ai-nlp/yelp_review_full_csv.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABEJF3J0VaUC"
   },
   "source": [
    "Following code Unzips the downloaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "z5pM8loFQ8ZV",
    "outputId": "6d8298c8-580c-4de4-c2aa-f7f8fa3567b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "filename=\"./yelp_review_full_csv.tgz\"\n",
    "with tarfile.open(filename,\"r\") as tar:\n",
    "  tar.extractall()\n",
    "  print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ov6xH3WHaPsz"
   },
   "source": [
    "### Importing Data\n",
    "We have two datasets namely test.csv and train.csv.\n",
    "Let's quickly load them using Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4HdLcI5QRhXv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train=pd.read_csv(\"./yelp_review_full_csv/train.csv\",nrows=200000,names=[\"labels\",\"sentences\"])\n",
    "df_test=pd.read_csv(\"./yelp_review_full_csv/test.csv\",nrows=25000,names=[\"labels\",\"sentences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fsw5hQnFcWm5"
   },
   "source": [
    "We have 6 Lakh 50 thousand data points which is very good for training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "J3gY2SzDnNZN",
    "outputId": "69c0d1cf-1e93-470d-c33e-12e2dbe59e7c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>dr. goldberg offers everything i look for in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Got a letter in the mail last week that said D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                          sentences\n",
       "0       5  dr. goldberg offers everything i look for in a...\n",
       "1       2  Unfortunately, the frustration of being Dr. Go...\n",
       "2       4  Been going to Dr. Goldberg for over 10 years. ...\n",
       "3       4  Got a letter in the mail last week that said D...\n",
       "4       1  I don't know what Dr. Goldberg was like before..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mVodRiWCuKAA",
    "outputId": "84fb1309-c6d0-44b7-f826-690951b0e895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   labels     200000 non-null  int64 \n",
      " 1   sentences  200000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcqtNV2pdFD8"
   },
   "source": [
    "and we have 50 thousand datapoints for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9bMz37kKTkUv",
    "outputId": "6f7d03f0-d736-40d5-f97c-40723bc5574a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   labels     25000 non-null  int64 \n",
      " 1   sentences  25000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 390.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PLCteHHdZ1A"
   },
   "source": [
    "will checkout how many lables present in the model that we are gonna predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hUBCLvOSdpE-",
    "outputId": "5b3201fd-60a1-497f-fee7-dc32b152a577"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 4, 1, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.labels.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JoYNNgl5d0rP"
   },
   "source": [
    "We have 5 labels and they starts from index 1. For our convniences,will change the lables starting position from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BJllrEMqrvun"
   },
   "outputs": [],
   "source": [
    "df_train.labels=df_train.labels-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSIiN7pgeyEV"
   },
   "source": [
    "Storing sentences and values into a python list for further process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "n_tfL_1AT_Zi"
   },
   "outputs": [],
   "source": [
    "sentences=df_train.sentences.values\n",
    "labels=df_train.labels.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ux_4xkpfBSj"
   },
   "source": [
    "Let's do a quick anaysis, to find whether our dataset is well balanced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ke1nQ4DT-UhL",
    "outputId": "88ec69c7-765b-4792-cdc1-03429ce3693e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(df_train.labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JO93EWAZgjjC"
   },
   "source": [
    "Bert can handle 512 tokens as input,let's check how many sentences has token length more than 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hPzigpSTUevz",
    "outputId": "86fc518e-aae3-4f83-c142-18c8e345f4f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 3584 sentences having tokens longer than 512 \n"
     ]
    }
   ],
   "source": [
    "z=[]\n",
    "for i in sentences:\n",
    "  if len(i.split())>512:\n",
    "    z.append(len(i.split()))\n",
    "print(\"We have {} sentences having tokens longer than 512 \" .format(len(z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBDXASHbhdjB"
   },
   "source": [
    "### All right, before we begin let's understand the pipeline.\n",
    "\n",
    "1. Tokenization\n",
    "\n",
    "2. Make a datset\n",
    "\n",
    "3. Divide the dataset into batches\n",
    "\n",
    "4. Import pretrained BERT model\n",
    "\n",
    "5. Define optimizer and learning rate\n",
    "\n",
    "6. Train our model\n",
    "\n",
    "7. Evalauate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2slyLeykTaU"
   },
   "source": [
    "Since Bert model is already trained, we will use that same information for creating tokens for our model.\n",
    "\n",
    "Now you must know about **\"huggingface\"**,\n",
    "Huggingface is a brilliant source for many different model architectures for our NLP tasks.\n",
    "\n",
    "you can explore them using this link https://huggingface.co/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9L0J0Xk1Ui0D",
    "outputId": "e9c1f1e9-afcb-4390-e466-f5c1bb7b659e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Bert tokanizer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33e881ede234899aefe9b05ec0fabe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the bert tokenizer.\n",
    "print(\"Loading Bert tokanizer\")\n",
    "tokenizer=BertTokenizer.from_pretrained(\"bert-base-uncased\",do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsKrI5wHmAeZ"
   },
   "source": [
    "Creating tokens and ids for a single sentences for clear understanding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "VetUhfxYVavD",
    "outputId": "a47f9f26-c5a5-40dc-ff19-af2eb26f6470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original: dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\n",
      "534\n",
      " tokenized: ['dr', '.', 'goldberg', 'offers', 'everything', 'i', 'look', 'for', 'in', 'a', 'general', 'practitioner', '.', 'he', \"'\", 's', 'nice', 'and', 'easy', 'to', 'talk', 'to', 'without', 'being', 'patron', '##izing', ';', 'he', \"'\", 's', 'always', 'on', 'time', 'in', 'seeing', 'his', 'patients', ';', 'he', \"'\", 's', 'affiliated', 'with', 'a', 'top', '-', 'notch', 'hospital', '(', 'nyu', ')', 'which', 'my', 'parents', 'have', 'explained', 'to', 'me', 'is', 'very', 'important', 'in', 'case', 'something', 'happens', 'and', 'you', 'need', 'surgery', ';', 'and', 'you', 'can', 'get', 'refer', '##ral', '##s', 'to', 'see', 'specialists', 'without', 'having', 'to', 'see', 'him', 'first', '.', 'really', ',', 'what', 'more', 'do', 'you', 'need', '?', 'i', \"'\", 'm', 'sitting', 'here', 'trying', 'to', 'think', 'of', 'any', 'complaints', 'i', 'have', 'about', 'him', ',', 'but', 'i', \"'\", 'm', 'really', 'drawing', 'a', 'blank', '.']\n",
      "120\n",
      "Token IDs:  [2852, 1012, 18522, 4107, 2673, 1045, 2298, 2005, 1999, 1037, 2236, 18742, 1012, 2002, 1005, 1055, 3835, 1998, 3733, 2000, 2831, 2000, 2302, 2108, 9161, 6026, 1025, 2002, 1005, 1055, 2467, 2006, 2051, 1999, 3773, 2010, 5022, 1025, 2002, 1005, 1055, 6989, 2007, 1037, 2327, 1011, 18624, 2902, 1006, 27935, 1007, 2029, 2026, 3008, 2031, 4541, 2000, 2033, 2003, 2200, 2590, 1999, 2553, 2242, 6433, 1998, 2017, 2342, 5970, 1025, 1998, 2017, 2064, 2131, 6523, 7941, 2015, 2000, 2156, 15744, 2302, 2383, 2000, 2156, 2032, 2034, 1012, 2428, 1010, 2054, 2062, 2079, 2017, 2342, 1029, 1045, 1005, 1049, 3564, 2182, 2667, 2000, 2228, 1997, 2151, 10821, 1045, 2031, 2055, 2032, 1010, 2021, 1045, 1005, 1049, 2428, 5059, 1037, 8744, 1012]\n",
      "attention_masks: [101, 2852, 1012, 18522, 4107, 2673, 1045, 2298, 2005, 1999, 1037, 2236, 18742, 1012, 2002, 1005, 1055, 3835, 1998, 3733, 2000, 2831, 2000, 2302, 2108, 9161, 6026, 1025, 2002, 1005, 1055, 2467, 2006, 2051, 1999, 3773, 2010, 5022, 1025, 2002, 1005, 1055, 6989, 2007, 1037, 2327, 1011, 18624, 2902, 1006, 27935, 1007, 2029, 2026, 3008, 2031, 4541, 2000, 2033, 2003, 2200, 2590, 1999, 2553, 2242, 6433, 1998, 2017, 2342, 5970, 1025, 1998, 2017, 2064, 2131, 6523, 7941, 2015, 2000, 2156, 15744, 2302, 2383, 2000, 2156, 2032, 2034, 1012, 2428, 1010, 2054, 2062, 2079, 2017, 2342, 1029, 1045, 1005, 1049, 3564, 2182, 2667, 2000, 2228, 1997, 2151, 10821, 1045, 2031, 2055, 2032, 1010, 2021, 1045, 1005, 1049, 2428, 5059, 1037, 8744, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# print the original sentence\n",
    "print(\" Original:\", sentences[0])\n",
    "print(len(sentences[0]))\n",
    "\n",
    "# print the sentence split into tokens\n",
    "print(\" tokenized:\",tokenizer.tokenize(sentences[0]))\n",
    "print(len(tokenizer.tokenize(sentences[0])))\n",
    "# print the sentence mapped to the token ids\n",
    "print(\"Token IDs: \", tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))\n",
    "max_length=300\n",
    "print(\"attention_masks:\",tokenizer.encode(sentences[0], add_special_tokens=True,truncation=True,\n",
    "                          return_attention_masks=True,padding = \"max_length\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3aEZbb3nR4Q"
   },
   "source": [
    "Here is the code for creating inputs ids and attention masks for entire sentences in our dataset.\n",
    "\n",
    "I have used max length to 150 to avoid \"cuda out of memory error\".\n",
    "\n",
    "If you have good GPU then you can free to use full length of tokens, sorry 512 tokens max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "n6AvBxMRX0VF",
    "outputId": "28656123-47d8-432b-9f3a-fe333b2db47e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\n",
      "Token IDs: tensor([  101,  2852,  1012, 18522,  4107,  2673,  1045,  2298,  2005,  1999,\n",
      "         1037,  2236, 18742,  1012,  2002,  1005,  1055,  3835,  1998,  3733,\n",
      "         2000,  2831,  2000,  2302,  2108,  9161,  6026,  1025,  2002,  1005,\n",
      "         1055,  2467,  2006,  2051,  1999,  3773,  2010,  5022,  1025,  2002,\n",
      "         1005,  1055,  6989,  2007,  1037,  2327,  1011, 18624,  2902,  1006,\n",
      "        27935,  1007,  2029,  2026,  3008,  2031,  4541,  2000,  2033,  2003,\n",
      "         2200,  2590,  1999,  2553,  2242,  6433,  1998,  2017,  2342,  5970,\n",
      "         1025,  1998,  2017,  2064,  2131,  6523,  7941,  2015,  2000,  2156,\n",
      "        15744,  2302,  2383,  2000,  2156,  2032,  2034,  1012,  2428,  1010,\n",
      "         2054,  2062,  2079,  2017,  2342,  1029,  1045,  1005,  1049,  3564,\n",
      "         2182,  2667,  2000,  2228,  1997,  2151, 10821,  1045,  2031,  2055,\n",
      "         2032,  1010,  2021,  1045,  1005,  1049,  2428,  5059,  1037,  8744,\n",
      "         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]\n",
    "                        # padding=True,\n",
    "                        max_length = 200,          # Pad & truncate all sentences.\n",
    "                        truncation= True,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',    # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6hLzQdQpk6N"
   },
   "source": [
    "Creating a Tensor dataset and spliting it for traing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "nD8cf43RdXip",
    "outputId": "ed5148c5-a2d4-448b-eab2-2ba970c413f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160,000 training samples\n",
      "40,000 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "#combine the training inputs into tensordataset\n",
    "dataset = TensorDataset(input_ids,attention_masks,labels)\n",
    "\n",
    "#create a 80-20 train-validation split\n",
    "\n",
    "\n",
    "#calculate the number of samples to include in each set.\n",
    "train_size=int(0.8*len(dataset))\n",
    "val_size=len(dataset)-train_size\n",
    "\n",
    "#divide the dataset by randomly selecting samples.\n",
    "train_dataset,val_dataset=random_split(dataset,[train_size,val_size])\n",
    "\n",
    "print(\"{:>5,} training samples\".format(train_size))\n",
    "print(\"{:>5,} validation samples\".format(val_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTgLOKvKzLlR"
   },
   "source": [
    "Here we are creating dataloader of batch size 32.We wil take traing samples in random order and for validation we will read it sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "eK2crIUMpcSS"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler,SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    sampler=RandomSampler(train_dataset), \n",
    "    batch_size=batch_size\n",
    "    )\n",
    "\n",
    "validation_dataloader=DataLoader(\n",
    "    val_dataset, \n",
    "    sampler=SequentialSampler(val_dataset), \n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-pRVhEE0paz"
   },
   "source": [
    "Will Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top and we will modify the classification layer to predict for 5 classes.\n",
    "\n",
    "Moving the model into GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Lk0LVdUvNdKe",
    "outputId": "66a07724-0483-4149-9e71-b7ed08c0e1ab"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb08aeb371342b089d7f04cac7b1f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f15ae125c0497fb29e4bb1973aff54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 5, # The number of output labels--2 for binary classification. \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# moving this model to the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrcDdrD01o4A"
   },
   "source": [
    "Just out of curiousity we are checking model parameters and it's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bxQ-i35tWLgv",
    "outputId": "fdaa4e44-fc3d-4b29-8a40-217c0015a38b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (5, 768)\n",
      "classifier.bias                                                 (5,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2QjHat53CXV"
   },
   "source": [
    "We are gonna use AdamW as an optimizer and it is a class from the huggingface library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "G1uz4dQeYWQP"
   },
   "outputs": [],
   "source": [
    "optimizer=AdamW(model.parameters(),\n",
    "                lr=2e-5, #args.learning rate-default is 5e-5,our note book has 2e-5\n",
    "                eps=1e-8 #args.adam_epsilon --default is le-8\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soG_xQ-p3eaQ"
   },
   "source": [
    "The BERT authors recommend between 2 and 4 epochs. \n",
    "We chose to run for 2, but we'll see later that this may be over-fitting or underfitting the trianing data\n",
    "\n",
    "we will use scheduler function for updating the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "bSLvVOUYZpUY"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "epochs = 2\n",
    "#  Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples)\n",
    "\n",
    "total_steps=len(train_dataloader)*epochs\n",
    "\n",
    "scheduler =get_linear_schedule_with_warmup(optimizer,\n",
    "                                           num_warmup_steps =0,#default values is run_glue.py\n",
    "                                           num_training_steps =total_steps\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GEDsg8qENBp"
   },
   "source": [
    "Function to calculate the accuracy of our predictions vs labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "37GAYHaqayam"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXwypT2CEdv4"
   },
   "source": [
    "Create a function to track the time in our model while traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "re-mwBzjbdYS"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "\n",
    "  '''\n",
    "  Takes a time in seconds and returns a string hh:mm:ss\n",
    "  '''\n",
    "\n",
    "  #Round to the nearest second\n",
    "  elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "  # Format as hh:mm:ss\n",
    "  return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Ptx3T2_9msm9"
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZmtvZzZFFRc"
   },
   "source": [
    "### Here is the complete code for traning our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2lgggY3wcnkP",
    "outputId": "7375aade-f7bc-4adc-d64e-1ab9aa23d500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch   100  of  5,000.    Elapsed: 0:01:01.\n",
      "  Batch   200  of  5,000.    Elapsed: 0:02:02.\n",
      "  Batch   300  of  5,000.    Elapsed: 0:03:02.\n",
      "  Batch   400  of  5,000.    Elapsed: 0:04:02.\n",
      "  Batch   500  of  5,000.    Elapsed: 0:05:03.\n",
      "  Batch   600  of  5,000.    Elapsed: 0:06:03.\n",
      "  Batch   700  of  5,000.    Elapsed: 0:07:03.\n",
      "  Batch   800  of  5,000.    Elapsed: 0:08:04.\n",
      "  Batch   900  of  5,000.    Elapsed: 0:09:04.\n",
      "  Batch 1,000  of  5,000.    Elapsed: 0:10:04.\n",
      "  Batch 1,100  of  5,000.    Elapsed: 0:11:05.\n",
      "  Batch 1,200  of  5,000.    Elapsed: 0:12:05.\n",
      "  Batch 1,300  of  5,000.    Elapsed: 0:13:05.\n",
      "  Batch 1,400  of  5,000.    Elapsed: 0:14:06.\n",
      "  Batch 1,500  of  5,000.    Elapsed: 0:15:06.\n",
      "  Batch 1,600  of  5,000.    Elapsed: 0:16:06.\n",
      "  Batch 1,700  of  5,000.    Elapsed: 0:17:07.\n",
      "  Batch 1,800  of  5,000.    Elapsed: 0:18:07.\n",
      "  Batch 1,900  of  5,000.    Elapsed: 0:19:07.\n",
      "  Batch 2,000  of  5,000.    Elapsed: 0:20:08.\n",
      "  Batch 2,100  of  5,000.    Elapsed: 0:21:08.\n",
      "  Batch 2,200  of  5,000.    Elapsed: 0:22:08.\n",
      "  Batch 2,300  of  5,000.    Elapsed: 0:23:09.\n",
      "  Batch 2,400  of  5,000.    Elapsed: 0:24:09.\n",
      "  Batch 2,500  of  5,000.    Elapsed: 0:25:09.\n",
      "  Batch 2,600  of  5,000.    Elapsed: 0:26:09.\n",
      "  Batch 2,700  of  5,000.    Elapsed: 0:27:10.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 100 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # It returns different numbers of parameters depending on what arguments\n",
    "        # arge given and what flags are set. For our useage here, it returns\n",
    "        # the loss (because we provided labels) and the \"logits\"--the model\n",
    "        # outputs prior to activation.\n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "            # values prior to applying an activation function like the softmax.\n",
    "            (loss, logits) = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvdPac5_HcPx"
   },
   "source": [
    "Create a DataFrame from our training statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5fNp2U7WiNrz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('precision', 2)\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0hRZ-VMICMz"
   },
   "source": [
    "Plotting Learning curve vs validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLFJC_MIjnvQ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSmMhGNcIYl5"
   },
   "source": [
    "Now we will prepare the dataloader usig testing dataset for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aP4-qrsAj0jO"
   },
   "outputs": [],
   "source": [
    "\n",
    "print('Number of test sentences: {:,}\\n'.format(df_test.shape[0]))\n",
    "\n",
    "\n",
    "sentences = df_test.sentences.values\n",
    "labels = df_test.labels.values\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sentences:\n",
    "  encoded_dict = tokenizer.encode_plus(\n",
    "                        sent[0:200],                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 200,\n",
    "                        truncation=True,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "  input_ids.append(encoded_dict['input_ids'])\n",
    "  attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    " \n",
    "batch_size = 32  \n",
    "\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9TDeUm1JtJq"
   },
   "source": [
    "following code will be used for evaluating our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F2R-wrGRj1mW"
   },
   "outputs": [],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "predictions , true_labels = [], []\n",
    "\n",
    "for batch in prediction_dataloader:\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k1KDD1Kg3EG4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "for i in range(len(true_labels)):\n",
    "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "  matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCvWqGCL3085"
   },
   "outputs": [],
   "source": [
    "# Create a barplot showing the MCC score for each batch of test samples.\n",
    "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
    "\n",
    "plt.title('MCC Score per Batch')\n",
    "plt.ylabel('MCC Score (-1 to +1)')\n",
    "plt.xlabel('Batch #')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bb2v0o6V36Xo"
   },
   "outputs": [],
   "source": [
    "# Combine the results across all batches. \n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('Total MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSK2t6iSLvEw"
   },
   "source": [
    "# Saving our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viDBICx54A8N"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "output_dir = './model_save/'\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Good practice: save your training arguments together with the trained model\n",
    "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CsL2VuzMBGV"
   },
   "source": [
    "# saving our model into google drive for future use and deployment purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ufrri3Pj8svb"
   },
   "outputs": [],
   "source": [
    "# Copy the model files to a directory in your Google Drive.\n",
    "!cp -r ./model_save/ \"bert_yelp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LawKM74vMAaF"
   },
   "source": [
    "# Loading saved model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "polT8c6wDctk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertConfig,BertForSequenceClassification,BertTokenizer\n",
    "config = BertConfig.from_json_file(\"config.json\")\n",
    "model = BertForSequenceClassification(config)\n",
    "state_dict = torch.load(\"pytorch_model.bin\")\n",
    "model.load_state_dict(state_dict)\n",
    "tokenizer = BertTokenizer(\"vocab.txt\", do_lower_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0gpmy5YvU2Y"
   },
   "outputs": [],
   "source": [
    "def sentiment_anaysis():\n",
    "  input_sentence=input()\n",
    "  ratings=[\"Worst\",\"Poor\",\"Average\",\"Good\",\"Excellent\"]\n",
    "  encoded_dict=tokenizer.encode_plus(input_sentence,add_special_tokens=True,max_length=250,\n",
    "                                    truncation=True,padding=\"max_length\",return_attention_mask=True,return_tensors=\"pt\")\n",
    "  input_ids=encoded_dict[\"input_ids\"]\n",
    "  attention_masks=encoded_dict[\"attention_mask\"]\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    output=model(input_ids, token_type_ids=None, \n",
    "                        attention_mask=attention_masks)\n",
    "    out=ratings[np.argmax(output[0][0].numpy())]\n",
    "  print(\"\\nyou have given {} ratings\".format(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWYkH0q_iGYf"
   },
   "outputs": [],
   "source": [
    "sentiment_anaysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uc__FMOerorp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_cn3n5o86Wx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GskwKSTqA2Hr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UtaHg2bI9Kod"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E1sywW9C9Klh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xt47N7smqQTA"
   },
   "outputs": [],
   "source": [
    "sentiment_anaysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwnDHoRi5OxA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
